{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG-RSA Exploratory Analysis\n",
    "\n",
    "This notebook provides a template for exploratory analysis of EEG data using Representational Similarity Analysis (RSA).\n",
    "\n",
    "Based on Wilson et al. methodology for comparing imagery and perception representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mne\n",
    "\n",
    "from preprocessing import load_raw_eeg, preprocess_raw, create_epochs\n",
    "from features import extract_all_features\n",
    "from rsa import compute_rdm, create_imagery_perception_model, visualize_rdm\n",
    "from analysis import run_full_analysis\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw EEG data\n",
    "data_path = '../data/raw/subject_01.bdf'  # Update with your file path\n",
    "\n",
    "raw = load_raw_eeg(data_path)\n",
    "\n",
    "# Plot raw data\n",
    "raw.plot(duration=10, n_channels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess: filter and re-reference\n",
    "raw_preprocessed = preprocess_raw(raw, l_freq=0.1, h_freq=40.0, notch_freq=50.0)\n",
    "\n",
    "# Plot power spectral density\n",
    "raw_preprocessed.plot_psd(fmax=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define events (update with your event codes)\n",
    "events = mne.find_events(raw_preprocessed)\n",
    "\n",
    "event_id = {\n",
    "    'imagery_face': 1,\n",
    "    'imagery_house': 2,\n",
    "    'perception_face': 3,\n",
    "    'perception_house': 4\n",
    "}\n",
    "\n",
    "# Create epochs\n",
    "epochs = create_epochs(raw_preprocessed, events, event_id, \n",
    "                      tmin=-0.2, tmax=1.0, baseline=(-0.2, 0))\n",
    "\n",
    "print(f'Created {len(epochs)} epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ERPs\n",
    "epochs.average().plot(spatial_colors=True, time_unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ERP and spectral features\n",
    "features_dict = extract_all_features(epochs, \n",
    "                                    include_erp=True,\n",
    "                                    include_spectral=True,\n",
    "                                    normalize=True)\n",
    "\n",
    "print(f'ERP features shape: {features_dict[\"erp\"].shape}')\n",
    "print(f'Spectral features shape: {features_dict[\"spectral\"].shape}')\n",
    "print(f'All features shape: {features_dict[\"all\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RDM for imagery condition\n",
    "imagery_epochs = epochs['imagery_face', 'imagery_house']\n",
    "imagery_features = extract_all_features(imagery_epochs, normalize=True)['all']\n",
    "\n",
    "# Average features by condition\n",
    "imagery_face_avg = imagery_features[epochs['imagery_face'].selection].mean(axis=0)\n",
    "imagery_house_avg = imagery_features[epochs['imagery_house'].selection].mean(axis=0)\n",
    "imagery_cond_features = np.vstack([imagery_face_avg, imagery_house_avg])\n",
    "\n",
    "rdm_imagery = compute_rdm(imagery_cond_features, metric='correlation')\n",
    "\n",
    "# Visualize\n",
    "visualize_rdm(rdm_imagery, labels=['Face', 'House'], title='Imagery RDM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RDM for perception condition\n",
    "perception_epochs = epochs['perception_face', 'perception_house']\n",
    "perception_features = extract_all_features(perception_epochs, normalize=True)['all']\n",
    "\n",
    "perception_face_avg = perception_features[epochs['perception_face'].selection].mean(axis=0)\n",
    "perception_house_avg = perception_features[epochs['perception_house'].selection].mean(axis=0)\n",
    "perception_cond_features = np.vstack([perception_face_avg, perception_house_avg])\n",
    "\n",
    "rdm_perception = compute_rdm(perception_cond_features, metric='correlation')\n",
    "\n",
    "visualize_rdm(rdm_perception, labels=['Face', 'House'], title='Perception RDM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Imagery and Perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Correlation between imagery and perception RDMs\n",
    "n = rdm_imagery.shape[0]\n",
    "triu_idx = np.triu_indices(n, k=1)\n",
    "\n",
    "imagery_vec = rdm_imagery[triu_idx]\n",
    "perception_vec = rdm_perception[triu_idx]\n",
    "\n",
    "corr, p_value = spearmanr(imagery_vec, perception_vec)\n",
    "\n",
    "print(f'Spearman correlation: r = {corr:.3f}, p = {p_value:.4f}')\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(imagery_vec, perception_vec, alpha=0.6)\n",
    "plt.plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
    "plt.xlabel('Imagery Dissimilarity')\n",
    "plt.ylabel('Perception Dissimilarity')\n",
    "plt.title(f'Imagery vs Perception (r = {corr:.3f})')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsa import create_imagery_perception_model, compare_models\n",
    "\n",
    "# Create theoretical models\n",
    "condition_types = ['imagery', 'imagery', 'perception', 'perception']\n",
    "stimulus_types = ['face', 'house', 'face', 'house']\n",
    "\n",
    "models = create_imagery_perception_model(condition_types, stimulus_types)\n",
    "\n",
    "# Compare with data\n",
    "# Concatenate imagery and perception RDMs\n",
    "combined_rdm = np.block([[rdm_imagery, np.ones((2,2))],\n",
    "                        [np.ones((2,2)), rdm_perception]])\n",
    "\n",
    "results = compare_models(combined_rdm, models)\n",
    "\n",
    "# Plot results\n",
    "model_names = list(results.keys())\n",
    "correlations = [results[m][0] for m in model_names]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, correlations)\n",
    "plt.ylabel('Correlation with Data')\n",
    "plt.title('Model Comparison')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save RDMs\n",
    "np.save('../data/outputs/rdm_imagery.npy', rdm_imagery)\n",
    "np.save('../data/outputs/rdm_perception.npy', rdm_perception)\n",
    "\n",
    "# Save epochs\n",
    "imagery_epochs.save('../data/preprocessed/imagery_epochs-epo.fif', overwrite=True)\n",
    "perception_epochs.save('../data/preprocessed/perception_epochs-epo.fif', overwrite=True)\n",
    "\n",
    "print('Results saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
